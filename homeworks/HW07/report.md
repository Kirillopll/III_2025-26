# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

В работе были выбраны 3 датасета из 4.

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: ~12 000 строк, 9 столбцов (включая `sample_id`)
- Признаки: все признаки числовые
- Пропуски: отсутствуют
- "Подлости" датасета:
  - признаки находятся в сильно разных шкалах;
  - присутствуют шумовые признаки;
  - без масштабирования расстояния становятся некорректными, что сильно влияет на качество кластеризации.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: ~6 000 строк, 10 столбцов (включая `sample_id`)
- Признаки: все признаки числовые
- Пропуски: отсутствуют
- "Подлости" датасета:
  - нелинейная структура кластеров;
  - наличие выбросов;
  - присутствует дополнительный шумовой признак, ухудшающий работу геометрических методов.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер: ~5 000 строк, более 20 столбцов (включая `sample_id`)
- Признаки: числовые и категориальные
- Пропуски: присутствуют в числовых признаках
- "Подлости" датасета:
  - высокая размерность пространства признаков;
  - наличие категориальных признаков;
  - пропуски в данных требуют аккуратного препроцессинга;
  - расстояния в исходном пространстве плохо интерпретируемы без масштабирования.

---

## 2. Protocol

В работе использовался "честный" unsupervised-протокол без применения истинных меток.

- Препроцессинг:
  - числовые признаки: заполнение пропусков медианой + StandardScaler;
  - категориальные признаки (dataset-04): заполнение наиболее частым значением + OneHotEncoder;
  - PCA применялся **только для визуализации**, а не для обучения моделей.
- Поиск гиперпараметров:
  - для KMeans перебиралось число кластеров `k` в диапазоне от 2 до 10;
  - для DBSCAN подбирался параметр `eps` из нескольких значений при фиксированном `min_samples`;
  - для AgglomerativeClustering фиксировалось число кластеров `k` и использовался linkage `ward`.
- Выбор лучшего решения:
  - основным ориентиром служила метрика silhouette_score;
  - дополнительно анализировались Davies-Bouldin и Calinski-Harabasz;
  - для DBSCAN метрики считались **только по non-noise точкам** (label ≠ -1).
- Визуализация:
  - для каждого датасета построена PCA(2D) проекция с раскраской по кластерам;
  - дополнительно строились графики зависимости silhouette от параметров (k или eps).

---

## 3. Models

Для каждого датасета сравнивались следующие модели:

- **KMeans**
  - подбиралось число кластеров `k`;
  - фиксированы `random_state` и `n_init`;
- **DBSCAN**
  - подбирался параметр `eps`;
  - анализировалась доля шумовых точек;
- **AgglomerativeClustering**
  - фиксировалось число кластеров `k`;
  - использовался linkage `ward`.

Таким образом, для каждого датасета были представлены методы из разных семейств:
геометрический (KMeans), плотностной (DBSCAN) и иерархический.

---

## 4. Results

### 4.1 Dataset A

- Лучший метод и параметры:
  - KMeans, `k = 2`
- Метрики:
  - silhouette / Davies-Bouldin / Calinski-Harabasz показывают стабильное разбиение
- DBSCAN:
  - доля шума близка к 1, метод фактически не смог выделить кластеры
- Комментарий:
  - датасет хорошо описывается двумя крупными кластерами после масштабирования,
    что делает KMeans уместным выбором.

### 4.2 Dataset B

- Лучший метод и параметры:
  - DBSCAN с подобранным `eps`
- Метрики:
  - silhouette и Davies-Bouldin улучшаются по сравнению с KMeans
- DBSCAN:
  - часть точек отнесена к шуму, что соответствует наличию выбросов
- Комментарий:
  - нелинейная структура и выбросы делают DBSCAN более подходящим,
    чем KMeans с его предположением о сферической форме кластеров.

### 4.3 Dataset C

- Лучший метод и параметры:
  - KMeans после полного препроцессинга
- Метрики:
  - приемлемые значения всех внутренних метрик
- DBSCAN:
  - чувствителен к высокой размерности и даёт нестабильные результаты
- Комментарий:
  - аккуратный препроцессинг (imputation + encoding + scaling)
    оказался ключевым фактором для получения разумной кластеризации.

---

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans плохо работает без масштабирования и при наличии нелинейных структур.
- DBSCAN выигрывает на данных с выбросами и кластерами сложной формы,
  но чувствителен к выбору параметров.
- AgglomerativeClustering даёт интерпретируемые результаты,
  но хуже масштабируется по числу объектов.
- На результат сильнее всего влияли масштабирование признаков,
  наличие выбросов и высокая размерность.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка устойчивости проводилась для Dataset A.
- Выполнено 5 запусков KMeans с разными `random_state`.
- Сходство разбиений оценивалось с помощью Adjusted Rand Index (ARI).
- Значения ARI оказались близки к 1, что говорит о высокой устойчивости разбиения.
- Вывод: кластеризация KMeans для данного датасета является устойчивой.

### 5.3 Интерпретация кластеров

- Кластеры интерпретировались через анализ распределений и масштабов признаков.
- В Dataset A кластеры соответствуют двум крупным группам с различными диапазонами значений.
- В Dataset B DBSCAN отделяет плотные области данных от выбросов.
- В Dataset C кластеры отражают совокупное влияние числовых и категориальных признаков.

---

## 6. Conclusion

- Кластеризация сильно зависит от масштаба признаков и качества препроцессинга.
- Внутренние метрики не универсальны и требуют аккуратной интерпретации.
- DBSCAN эффективно работает с выбросами, но чувствителен к параметрам.
- KMeans прост и устойчив, но ограничен предположением о форме кластеров.
- PCA полезна для визуализации, но не является доказательством качества.
- Честный unsupervised-протокол необходим для корректных выводов.
