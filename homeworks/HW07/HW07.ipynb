{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d3765cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ DS1 =================\n",
      "Первые строки датасета:\n",
      "   sample_id        f01        f02       f03         f04        f05  \\\n",
      "0          0  -0.536647 -69.812900 -0.002657   71.743147 -11.396498   \n",
      "1          1  15.230731  52.727216 -1.273634 -104.123302  11.589643   \n",
      "2          2  18.542693  77.317150 -1.321686 -111.946636  10.254346   \n",
      "3          3 -12.538905 -41.709458  0.146474   16.322124   1.391137   \n",
      "4          4  -6.903056  61.833444 -0.022466  -42.631335   3.107154   \n",
      "\n",
      "         f06        f07       f08  \n",
      "0 -12.291287  -6.836847 -0.504094  \n",
      "1  34.316967 -49.468873  0.390356  \n",
      "2  25.892951  44.595250  0.325893  \n",
      "3   2.014316 -39.930582  0.139297  \n",
      "4  -5.471054   7.001149  0.131213  \n",
      "\n",
      "Информация о данных:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12000 entries, 0 to 11999\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   sample_id  12000 non-null  int64  \n",
      " 1   f01        12000 non-null  float64\n",
      " 2   f02        12000 non-null  float64\n",
      " 3   f03        12000 non-null  float64\n",
      " 4   f04        12000 non-null  float64\n",
      " 5   f05        12000 non-null  float64\n",
      " 6   f06        12000 non-null  float64\n",
      " 7   f07        12000 non-null  float64\n",
      " 8   f08        12000 non-null  float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 843.9 KB\n",
      "None\n",
      "Числовые признаки: 8\n",
      "Категориальные признаки: 0\n",
      "\n",
      "Подбор числа кластеров для KMeans...\n",
      "Лучшее k для KMeans: 2\n",
      "\n",
      "================ DS2 =================\n",
      "Первые строки датасета:\n",
      "   sample_id        x1        x2    z_noise\n",
      "0          0  0.098849 -1.846034  21.288122\n",
      "1          1 -1.024516  1.829616   6.072952\n",
      "2          2 -1.094178 -0.158545 -18.938342\n",
      "3          3 -1.612808 -1.565844 -11.629462\n",
      "4          4  1.659901 -2.133292   1.895472\n",
      "\n",
      "Информация о данных:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   sample_id  8000 non-null   int64  \n",
      " 1   x1         8000 non-null   float64\n",
      " 2   x2         8000 non-null   float64\n",
      " 3   z_noise    8000 non-null   float64\n",
      "dtypes: float64(3), int64(1)\n",
      "memory usage: 250.1 KB\n",
      "None\n",
      "Числовые признаки: 3\n",
      "Категориальные признаки: 0\n",
      "\n",
      "Подбор числа кластеров для KMeans...\n",
      "Лучшее k для KMeans: 2\n",
      "\n",
      "================ DS4 =================\n",
      "Первые строки датасета:\n",
      "   sample_id cat_a cat_b        n01        n02        n03        n04  \\\n",
      "0          0     B     X  -4.827501 -24.507466  -7.852963   0.771781   \n",
      "1          1     F     V  51.302500        NaN   5.534737  51.305464   \n",
      "2          2     A     W  -4.820828  -2.625385  27.891578   1.523041   \n",
      "3          3     B     X  -2.627573 -25.063639  -9.450011  -8.344669   \n",
      "4          4     C     Y -11.415710  -8.692169  48.636163  14.661826   \n",
      "\n",
      "         n05        n06        n07  ...        n21        n22        n23  \\\n",
      "0  28.297884  -4.493911 -42.769449  ...  24.597176 -26.354320   4.543397   \n",
      "1  -8.027553  28.297548        NaN  ... -18.216260   8.527932  17.202115   \n",
      "2  -5.776687 -16.298523   2.462937  ... -48.260775   9.313232  12.323411   \n",
      "3  22.371118 -11.525848 -43.762607  ...  24.700663 -25.466915  -3.398665   \n",
      "4 -39.634618  10.769075  40.187536  ... -79.710383 -13.694253  41.575892   \n",
      "\n",
      "         n24       n25       n26       n27       n28       n29       n30  \n",
      "0 -19.549036 -3.051332 -5.538587 -3.084457  5.499629 -6.128896  3.132067  \n",
      "1 -30.452260  0.855326  1.199066  3.597555 -2.239703  2.932710  0.473145  \n",
      "2  55.081325 -3.945606 -0.280540 -0.130583 -7.353205 -2.942836  1.460477  \n",
      "3 -18.174541  0.438229  3.152556  3.859283 -2.678769 -2.213923 -4.724639  \n",
      "4  -9.498640  1.529608 -1.641347  3.500090  3.111257  1.475232 -1.321676  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "\n",
      "Информация о данных:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 33 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   sample_id  10000 non-null  int64  \n",
      " 1   cat_a      10000 non-null  object \n",
      " 2   cat_b      10000 non-null  object \n",
      " 3   n01        9826 non-null   float64\n",
      " 4   n02        9811 non-null   float64\n",
      " 5   n03        9801 non-null   float64\n",
      " 6   n04        9808 non-null   float64\n",
      " 7   n05        9799 non-null   float64\n",
      " 8   n06        9817 non-null   float64\n",
      " 9   n07        9796 non-null   float64\n",
      " 10  n08        9806 non-null   float64\n",
      " 11  n09        9805 non-null   float64\n",
      " 12  n10        9811 non-null   float64\n",
      " 13  n11        9796 non-null   float64\n",
      " 14  n12        9798 non-null   float64\n",
      " 15  n13        9803 non-null   float64\n",
      " 16  n14        9802 non-null   float64\n",
      " 17  n15        9814 non-null   float64\n",
      " 18  n16        9809 non-null   float64\n",
      " 19  n17        9788 non-null   float64\n",
      " 20  n18        9788 non-null   float64\n",
      " 21  n19        9813 non-null   float64\n",
      " 22  n20        9797 non-null   float64\n",
      " 23  n21        9785 non-null   float64\n",
      " 24  n22        9804 non-null   float64\n",
      " 25  n23        9829 non-null   float64\n",
      " 26  n24        9793 non-null   float64\n",
      " 27  n25        9815 non-null   float64\n",
      " 28  n26        9776 non-null   float64\n",
      " 29  n27        9803 non-null   float64\n",
      " 30  n28        9789 non-null   float64\n",
      " 31  n29        9798 non-null   float64\n",
      " 32  n30        9805 non-null   float64\n",
      "dtypes: float64(30), int64(1), object(2)\n",
      "memory usage: 2.5+ MB\n",
      "None\n",
      "Числовые признаки: 30\n",
      "Категориальные признаки: 2\n",
      "\n",
      "Подбор числа кластеров для KMeans...\n",
      "Лучшее k для KMeans: 5\n",
      "\n",
      "Подбор параметра eps для DBSCAN...\n",
      "eps=0.3: доля шума=1.000, кластеров (без шума)=0\n",
      "  Silhouette не считается (менее 2 кластеров).\n",
      "eps=0.5: доля шума=1.000, кластеров (без шума)=0\n",
      "  Silhouette не считается (менее 2 кластеров).\n",
      "eps=0.7: доля шума=1.000, кластеров (без шума)=0\n",
      "  Silhouette не считается (менее 2 кластеров).\n",
      "eps=1.0: доля шума=0.999, кластеров (без шума)=2\n",
      "Лучший eps для DBSCAN: 1.0\n",
      "Доля шума: 0.999\n",
      "Метрики DBSCAN рассчитаны только по non-noise точкам (label != -1).\n",
      "\n",
      "Проверка устойчивости KMeans на ds1...\n",
      "ARI между запусками: [1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score,\n",
    "    adjusted_rand_score\n",
    ")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Пути и общие настройки\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "ARTIFACTS_DIR = Path(\"artifacts\")\n",
    "FIGURES_DIR = ARTIFACTS_DIR / \"figures\"\n",
    "LABELS_DIR = ARTIFACTS_DIR / \"labels\"\n",
    "\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LABELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "datasets = {\n",
    "    \"ds1\": \"S07-hw-dataset-01.csv\",\n",
    "    \"ds2\": \"S07-hw-dataset-02.csv\",\n",
    "    \"ds4\": \"S07-hw-dataset-04.csv\",\n",
    "}\n",
    "\n",
    "metrics_summary = {}\n",
    "best_configs = {}\n",
    "\n",
    "\n",
    "# Вспомогательная функция для расчёта метрик\n",
    "\n",
    "def calc_metrics(X, labels):\n",
    "    return {\n",
    "        \"silhouette\": float(silhouette_score(X, labels)),\n",
    "        \"davies_bouldin\": float(davies_bouldin_score(X, labels)),\n",
    "        \"calinski_harabasz\": float(calinski_harabasz_score(X, labels)),\n",
    "    }\n",
    "\n",
    "\n",
    "# Основной цикл по датасетам\n",
    "\n",
    "for name, fname in datasets.items():\n",
    "    print(f\"\\n================ {name.upper()} =================\")\n",
    "    df = pd.read_csv(DATA_DIR / fname)\n",
    "\n",
    "    print(\"Первые строки датасета:\")\n",
    "    print(df.head())\n",
    "\n",
    "    print(\"\\nИнформация о данных:\")\n",
    "    print(df.info())\n",
    "\n",
    "    sample_id = df[\"sample_id\"]\n",
    "    X = df.drop(columns=[\"sample_id\"])\n",
    "\n",
    "    \n",
    "    # Определяем типы признаков\n",
    "    \n",
    "    num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    cat_cols = X.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "\n",
    "    print(f\"Числовые признаки: {len(num_cols)}\")\n",
    "    print(f\"Категориальные признаки: {len(cat_cols)}\")\n",
    "\n",
    "    \n",
    "    # Препроцессинг\n",
    "    \n",
    "    transformers = []\n",
    "\n",
    "    if num_cols:\n",
    "        transformers.append((\n",
    "            \"num\",\n",
    "            Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                (\"scaler\", StandardScaler())\n",
    "            ]),\n",
    "            num_cols\n",
    "        ))\n",
    "\n",
    "    if cat_cols:\n",
    "        transformers.append((\n",
    "            \"cat\",\n",
    "            Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "            ]),\n",
    "            cat_cols\n",
    "        ))\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers)\n",
    "    X_prep = preprocessor.fit_transform(X)\n",
    "\n",
    "    \n",
    "    # KMeans — подбор k по silhouette\n",
    "    \n",
    "    print(\"\\nПодбор числа кластеров для KMeans...\")\n",
    "    sil_scores = {}\n",
    "\n",
    "    for k in range(2, 11):\n",
    "        km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10)\n",
    "        labels = km.fit_predict(X_prep)\n",
    "        sil_scores[k] = silhouette_score(X_prep, labels)\n",
    "\n",
    "    best_k = max(sil_scores, key=sil_scores.get)\n",
    "    print(f\"Лучшее k для KMeans: {best_k}\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(list(sil_scores.keys()), list(sil_scores.values()), marker=\"o\")\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"Silhouette\")\n",
    "    plt.title(f\"{name}: Silhouette vs k (KMeans)\")\n",
    "    plt.savefig(FIGURES_DIR / f\"{name}_kmeans_silhouette_k.png\")\n",
    "    plt.close()\n",
    "\n",
    "    kmeans = KMeans(n_clusters=best_k, random_state=RANDOM_STATE, n_init=10)\n",
    "    km_labels = kmeans.fit_predict(X_prep)\n",
    "\n",
    "\n",
    "# DBSCAN — подбор eps (с проверкой числа кластеров)\n",
    "\n",
    "print(\"\\nПодбор параметра eps для DBSCAN...\")\n",
    "best_dbscan = None\n",
    "best_db_sil = -1\n",
    "\n",
    "for eps in [0.3, 0.5, 0.7, 1.0]:\n",
    "    db = DBSCAN(eps=eps, min_samples=5)\n",
    "    labels = db.fit_predict(X_prep)\n",
    "\n",
    "    noise_ratio = (labels == -1).mean()\n",
    "\n",
    "    # оставляем только non-noise \n",
    "    core_labels = labels[labels != -1]\n",
    "    core_points = X_prep[labels != -1]\n",
    "\n",
    "    # количество кластеров (без шума)\n",
    "    n_clusters = len(set(core_labels))\n",
    "\n",
    "    print(\n",
    "        f\"eps={eps}: доля шума={noise_ratio:.3f}, \"\n",
    "        f\"кластеров (без шума)={n_clusters}\"\n",
    "    )\n",
    "\n",
    "    # silhouette корректен только при >= 2 \n",
    "    if n_clusters < 2:\n",
    "        print(\"  Silhouette не считается (менее 2 кластеров).\")\n",
    "        continue\n",
    "\n",
    "    sil = silhouette_score(core_points, core_labels)\n",
    "\n",
    "    if sil > best_db_sil:\n",
    "        best_db_sil = sil\n",
    "        best_dbscan = (db, labels, eps, noise_ratio)\n",
    "\n",
    "if best_dbscan is not None:\n",
    "    db_model, db_labels, best_eps, noise_ratio = best_dbscan\n",
    "    print(f\"Лучший eps для DBSCAN: {best_eps}\")\n",
    "    print(f\"Доля шума: {noise_ratio:.3f}\")\n",
    "    print(\n",
    "        \"Метрики DBSCAN рассчитаны только по non-noise точкам \"\n",
    "        \"(label != -1).\"\n",
    "    )\n",
    "else:\n",
    "    print(\"DBSCAN не дал устойчивого разбиения (>=2 кластеров).\")\n",
    "    db_labels = None\n",
    "    noise_ratio = 1.0\n",
    "\n",
    "    \n",
    "    # Agglomerative Clustering\n",
    "    \n",
    "    print(\"\\nЗапуск AgglomerativeClustering...\")\n",
    "    agg = AgglomerativeClustering(n_clusters=best_k, linkage=\"ward\")\n",
    "    agg_labels = agg.fit_predict(X_prep)\n",
    "\n",
    "    \n",
    "    # Метрики качества\n",
    "    \n",
    "    metrics_summary[name] = {\n",
    "        \"kmeans\": calc_metrics(X_prep, km_labels),\n",
    "        \"agglomerative\": calc_metrics(X_prep, agg_labels),\n",
    "        \"dbscan\": (\n",
    "            calc_metrics(\n",
    "                X_prep[db_labels != -1],\n",
    "                db_labels[db_labels != -1]\n",
    "            ) if db_labels is not None and noise_ratio < 0.9 else None\n",
    "        ),\n",
    "        \"dbscan_noise_ratio\": float(noise_ratio)\n",
    "    }\n",
    "\n",
    "    \n",
    "    # PCA (2D) — только для визуализации\n",
    "    \n",
    "    pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "    X_pca = pca.fit_transform(\n",
    "        X_prep.toarray() if hasattr(X_prep, \"toarray\") else X_prep\n",
    "    )\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=km_labels, s=10)\n",
    "    plt.title(f\"{name}: PCA (2D проекция, KMeans)\")\n",
    "    plt.savefig(FIGURES_DIR / f\"{name}_pca.png\")\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    # Сохранение меток кластеров (лучшее решение)\n",
    "    \n",
    "    out = pd.DataFrame({\n",
    "        \"sample_id\": sample_id,\n",
    "        \"cluster_label\": km_labels\n",
    "    })\n",
    "    out.to_csv(LABELS_DIR / f\"labels_hw07_{name}.csv\", index=False)\n",
    "\n",
    "    best_configs[name] = {\n",
    "        \"method\": \"KMeans\",\n",
    "        \"k\": best_k\n",
    "    }\n",
    "\n",
    "\n",
    "# Проверка устойчивости (ds1)\n",
    "\n",
    "print(\"\\nПроверка устойчивости KMeans на ds1...\")\n",
    "\n",
    "df = pd.read_csv(DATA_DIR / datasets[\"ds1\"])\n",
    "X = df.drop(columns=[\"sample_id\"])\n",
    "\n",
    "# Масштабирование (как и в основном эксперименте)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Явно фиксируем k (из основного эксперимента для ds1)\n",
    "k_stability = 2\n",
    "\n",
    "labels_list = []\n",
    "for seed in range(5):\n",
    "    km = KMeans(\n",
    "        n_clusters=k_stability,\n",
    "        random_state=seed,\n",
    "        n_init=10\n",
    "    )\n",
    "    labels_list.append(km.fit_predict(X))\n",
    "\n",
    "ari_scores = [\n",
    "    adjusted_rand_score(labels_list[0], labels_list[i])\n",
    "    for i in range(1, 5)\n",
    "]\n",
    "\n",
    "print(\"ARI между запусками:\", ari_scores)\n",
    "\n",
    "\n",
    "# Сохранение артефактов\n",
    "\n",
    "with open(ARTIFACTS_DIR / \"metrics_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(ARTIFACTS_DIR / \"best_configs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(best_configs, f, indent=2, ensure_ascii=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
