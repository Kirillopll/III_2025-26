# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Выбран датасет: `S06-hw-dataset-02.csv`
- Размер: ~2000 строк, 39 столбцов (включая `id` и `target`)
- Целевая переменная: `target` (бинарная классификация, классы 0 и 1, умеренный дисбаланс)
- Признаки: в основном числовые признаки (вещественные значения), а также несколько
  признаков, моделирующих нелинейные взаимодействия между исходными переменными

Датасет является синтетическим и специально сконструирован для демонстрации
преимуществ нелинейных моделей и ансамблей по сравнению с линейными алгоритмами.

---

## 2. Protocol

- Разбиение данных:
  - train / test = 75% / 25%
  - `random_state = 42`
  - использована стратификация по целевой переменной (`stratify=y`)
- Подбор гиперпараметров:
  - выполнялся **только на train-выборке**
  - использован `GridSearchCV` с 5-фолдовой кросс-валидацией
  - оптимизировалась метрика ROC-AUC
- Метрики качества:
  - **accuracy** — базовая метрика для ориентира
  - **F1-score** — учитывает баланс precision и recall
  - **ROC-AUC** — основная метрика для бинарной классификации,
    устойчива к дисбалансу классов и отражает качество ранжирования

Test-выборка использовалась **один раз** — только для финальной оценки моделей.

---

## 3. Models

В рамках работы были обучены и сравнены следующие модели:

- **DummyClassifier**
  - baseline с предсказанием наиболее частого класса
- **LogisticRegression**
  - использована в пайплайне со `StandardScaler`
  - выступает линейным baseline из предыдущего семинара
- **DecisionTreeClassifier**
  - подбирались гиперпараметры `max_depth` и `min_samples_leaf`
  - контроль сложности необходим для борьбы с переобучением
- **RandomForestClassifier**
  - ансамбль деревьев решений (bagging)
  - подбирались `max_depth`, `min_samples_leaf`, `max_features`
- **GradientBoostingClassifier**
  - boosting-модель с последовательным улучшением ошибок
  - подбирались `n_estimators` и `learning_rate`

Все гиперпараметры подбирались исключительно на train-выборке с помощью CV.

---

## 4. Results

Финальные метрики качества на test-выборке:

- DummyClassifier — наихудшее качество, близкое к случайному
- LogisticRegression — заметно лучше dummy, но ограничена линейной природой
- DecisionTree — качество выше baseline, но чувствительна к переобучению
- RandomForest — стабильное улучшение за счёт ансамблирования
- **GradientBoosting — лучшая модель по ROC-AUC**

Победитель: **GradientBoostingClassifier**, выбран по максимальному значению ROC-AUC,
что делает его наиболее подходящей моделью для данной бинарной задачи.

---

## 5. Analysis

- Устойчивость:
  - при изменении `random_state` качество одиночного дерева заметно колеблется
  - ансамблевые модели (Random Forest и Gradient Boosting) показывают
    более стабильные результаты
- Ошибки:
  - confusion matrix для лучшей модели показывает разумный баланс
    между ложноположительными и ложноотрицательными ошибками
- Интерпретация:
  - проведён анализ permutation importance
  - наиболее важные признаки соответствуют признакам с нелинейными взаимодействиями,
    что согласуется с природой датасета и выбранной boosting-моделью

---

## 6. Conclusion

- Деревья решений без контроля сложности легко переобучаются
- Bagging (Random Forest) снижает variance и повышает стабильность моделей
- Boosting эффективно исправляет ошибки предыдущих моделей и часто даёт
  наилучшее качество
- Линейные модели ограничены при наличии сложных нелинейных зависимостей
- Честный ML-протокол (CV на train, единый test) критичен для корректной оценки
- Ансамблевые методы являются предпочтительным выбором для сложных задач классификации
